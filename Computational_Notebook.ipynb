{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXAM NUMBER: B263310\n",
    "\n",
    "# 1. Introduction\n",
    "\n",
    "Online platforms host thousands of users engaging in discussions on countless topics. Reddit, being one of the largest \"forum\"-based platforms, often sees users pride themselves on conducting “fact-based” discussions. Yet, in practice, evidence and data can fail to persuade when they clash with entrenched views. In this project, I focused on how evidence is used—or potentially misused—in Reddit discussions about a divisive figure: **Elon Musk**.\n",
    "\n",
    "**Key Idea**: Evidence can matter, but its impact often depends on whether participants share norms about its validity and are open to changing their minds. Otherwise, the same source, link, or data point can be marshalled to reinforce opposing opinions.\n",
    "\n",
    "In this notebook, I documented the process to:\n",
    "- Scrape Reddit data related to Elon Musk from selected subreddits (`r/technology`, `r/EnoughMuskSpam`).\n",
    "- Identify instances where commenters invoked *indicators* of evidence (primarily external links and specific keywords).\n",
    "- Analyze the overall sentiment surrounding these discussions using VADER and a method using OpenAI's GPT classifcation.\n",
    "- Prepare the interaction data (replies) for network visualization in Gephi.\n",
    "\n",
    "This notebook outlines the problem, my approach, the methods executed, and preliminary observations from the data, setting the stage for deeper analysis and visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. The Problem of Contradictory Interpretations\n",
    "\n",
    "One of the central puzzles motivating this project is that the exact same piece of information often supports contradictory viewpoints online. For example, a news article about a controversial policy might be used by two different commenters to “prove” opposite claims. In the context of Elon Musk, a tweet or statistic about Tesla, SpaceX, or X (formerly Twitter) could be interpreted as either:\n",
    "\n",
    "- Proof of mismanagement, inconsistency, or hypocrisy.\n",
    "- Evidence of visionary leadership confronting biased media or overcoming obstacles.\n",
    "\n",
    "This phenomenon likely occurs because:\n",
    "1.  **Preexisting Beliefs**: Users tend to process new information through the lens of their existing worldview and biases towards the subject.\n",
    "2.  **Community Norms**: Different online communities have varying standards for acceptable evidence. Some demand rigorous sources; others may rely more on anecdotes or assertions.\n",
    "3.  **Emotional Loading**: Topics surrounding influential and often polarizing individuals like Elon Musk frequently trigger strong loyalty or hostility, potentially overshadowing the neutral presentation of facts.\n",
    "\n",
    "My work explores how prevalent these dynamics are in the collected Reddit data, particularly looking for differences between subreddits with potentially different baseline attitudes towards Musk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Position and Main Argument\n",
    "\n",
    "I adopted the following position to guide this analysis:\n",
    "\n",
    "> **\"Evidence indicators alone do not guarantee persuasion online. If there are no shared community norms or incentives to engage with the substance of the evidence, users can reinterpret or dismiss it based on pre-existing biases. However, comparing subreddits with different prevailing sentiments might reveal variations in how evidence indicators correlate with engagement and tone.\"**\n",
    "\n",
    "This position reflects the common experience of browsing Reddit: some communities foster a culture where backing up claims is encouraged, while others feature more rhetorical or emotionally driven exchanges where links might serve primarily as tribal signals. By analyzing the collected data, I aimed to see whether:\n",
    "\n",
    "- Users in the selected subreddits (`r/technology`, `r/EnoughMuskSpam`) differ in how often they include links or evidence-related keywords.\n",
    "- Posts/comments containing these evidence indicators correlate with higher engagement (scores) or specific sentiment patterns.\n",
    "- Instances of the same URL being cited potentially align with divergent sentiment scores, hinting at contradictory usage (requiring further qualitative checks).\n",
    "\n",
    "Ultimately, I argue that the **role of evidence** in these online discussions is not just about its presence, but about **how** it's framed and received within specific community contexts or often that evidence its self is rarely the pressasive action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Research Questions\n",
    "\n",
    "I framed my inquiry using these concrete questions:\n",
    "\n",
    "1.  **RQ1**: To what extent did Reddit users in `r/technology` and `r/EnoughMuskSpam` include external evidence *indicators* (links, specific keywords) when discussing Elon Musk during the sampled period?\n",
    "2.  **RQ2**: Did posts/comments containing these evidence indicators correlate with higher levels of engagement (e.g., upvotes/scores) in these subreddits?\n",
    "3.  **RQ3**: Can instances be identified where the *same* external link (URL) was cited in comments with significantly different sentiment scores, suggesting contradictory interpretations?\n",
    "4.  **RQ4**: How did the patterns observed for RQ1, RQ2, and RQ3 differ between `r/technology` and `r/EnoughMuskSpam`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Methods and Computational Techniques\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Data Collection (Reddit Scraping)\n",
    "\n",
    "1.  **Subreddits Targeted**\n",
    "    *   I selected two subreddits known to frequently discuss Elon Musk but often with different prevailing viewpoints:\n",
    "        *   `r/technology`: A large, general tech news subreddit, likely containing a mix of opinions.\n",
    "        *   `r/EnoughMuskSpam`: A subreddit explicitly critical of Elon Musk.\n",
    "    *   This contrast allows for exploring RQ4 (differences between communities).\n",
    "\n",
    "2.  **Scraping Execution**\n",
    "    *   I used Python’s **PRAW** library to connect to the Reddit API.\n",
    "    *   I scraped posts matching the query \"Elon Musk\" within the `time_filter='month'` timeframe, limiting the collection to `post_limit_per_subreddit = 50` posts from each subreddit to keep the dataset manageable for this initial analysis.\n",
    "    *   For each selected post, I retrieved up to `comment_limit_per_post = 100` comments, including metadata like author, score, creation time, parent ID, and text.\n",
    "\n",
    "3.  **Data Storage and Preprocessing**\n",
    "    *   The raw scraped data (posts and comments) was compiled into a single list and then saved as a Pandas DataFrame to a CSV file (`reddit_data_Elon_Musk_YYYYMMDD_HHMMSS.csv`).\n",
    "    *   Basic preprocessing involved converting timestamps to datetime objects and handling potential missing values (e.g., `[deleted]` authors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('keys.env')\n",
    "\n",
    "import praw\n",
    "import pandas as pd\n",
    "import time\n",
    "import os # For environment variables\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Data Collection...\n",
      "PRAW Reddit instance created.\n",
      "\n",
      "--- Processing Subreddit: r/technology ---\n",
      "  Fetching post 1/50: 1jl7jtp - Elon Musk pressured Reddit’s CEO on content modera...\n",
      "    Fetched 100 comments for post 1jl7jtp\n",
      "  Fetching post 2/50: 1jm22rt - Elon Musk makes request to Reddit CEO to take down...\n",
      "    Fetched 100 comments for post 1jm22rt\n",
      "  Fetching post 3/50: 1j84l15 - Elon Musk Says X Outage Caused by ‘Massive Cyberat...\n",
      "    Fetched 100 comments for post 1j84l15\n",
      "  Fetching post 4/50: 1j6mkmi - FAA workers threatened with firing if they ‘impede...\n",
      "    Fetched 100 comments for post 1j6mkmi\n",
      "  Fetching post 5/50: 1jmxnez - Elon Musk's Alleged Meddling Sparks Reddit Backlas...\n"
     ]
    }
   ],
   "source": [
    "# 5.1.1 Data Collection Code\n",
    "import os\n",
    "print(\"Starting Data Collection...\")\n",
    "\n",
    "# --- Configuration ---\n",
    "\n",
    "REDDIT_CLIENT_ID = os.environ.get(\"REDDIT_CLIENT_ID\", \"YOUR_REDDIT_CLIENT_ID\") \n",
    "REDDIT_CLIENT_SECRET = os.environ.get(\"REDDIT_CLIENT_SECRET\", \"YOUR_REDDIT_CLIENT_SECRET\") \n",
    "REDDIT_USER_AGENT = os.environ.get(\"REDDIT_USER_AGENT\", \"YOUR_REDDIT_USER_AGENT\") \n",
    "\n",
    "# Subreddits to target (Example: one potentially more moderated, one less)\n",
    "# Choose subreddits relevant to topic (e.g., Elon Musk)\n",
    "# subreddit_list = [\"technology\", \"EnoughMuskSpam\", \"SpaceXLounge\", \"politics\", \"wallstreetbets\"]\n",
    "subreddit_list = [\"technology\", \"EnoughMuskSpam\"] # Keep it small initially\n",
    "\n",
    "# Search query\n",
    "search_query = \"Elon Musk\"\n",
    "\n",
    "# Time limit for search (e.g., 'month', 'year', 'all')\n",
    "# Use of 'all' might return too much data so starting small\n",
    "time_filter = 'month'\n",
    "\n",
    "# Limit number of posts per subreddit (to keep it manageable)\n",
    "post_limit_per_subreddit = 50 \n",
    "comment_limit_per_post = 100 # Max comments per post\n",
    "\n",
    "\n",
    "# --- PRAW Setup ---\n",
    "try:\n",
    "    reddit = praw.Reddit(\n",
    "        client_id=REDDIT_CLIENT_ID,\n",
    "        client_secret=REDDIT_CLIENT_SECRET,\n",
    "        user_agent=REDDIT_USER_AGENT\n",
    "    )\n",
    "    reddit.read_only = True\n",
    "    print(\"PRAW Reddit instance created.\")\n",
    "except Exception as e:\n",
    "    print(f\"Error creating PRAW instance: {e}\")\n",
    "    # Exit or handle error appropriately\n",
    "    reddit = None\n",
    "\n",
    "# --- Data Storage ---\n",
    "all_data = [] # List to hold dictionaries of posts and comments\n",
    "\n",
    "# --- Scraping Loop ---\n",
    "if reddit:\n",
    "    for sub_name in subreddit_list:\n",
    "        print(f\"\\n--- Processing Subreddit: r/{sub_name} ---\")\n",
    "        try:\n",
    "            subreddit = reddit.subreddit(sub_name)\n",
    "            post_count = 0\n",
    "            # Search for posts mentioning the query\n",
    "            for submission in subreddit.search(search_query, sort=\"relevance\", time_filter=time_filter, limit=post_limit_per_subreddit):\n",
    "                if post_count >= post_limit_per_subreddit:\n",
    "                    break\n",
    "                post_count += 1\n",
    "                print(f\"  Fetching post {post_count}/{post_limit_per_subreddit}: {submission.id} - {submission.title[:50]}...\")\n",
    "\n",
    "                # Store post data\n",
    "                post_author = submission.author.name if submission.author else \"[deleted]\"\n",
    "                all_data.append({\n",
    "                    'type': 'post',\n",
    "                    'id': submission.id,\n",
    "                    'subreddit': sub_name,\n",
    "                    'title': submission.title,\n",
    "                    'author': post_author,\n",
    "                    'created_utc': submission.created_utc,\n",
    "                    'score': submission.score,\n",
    "                    'upvote_ratio': submission.upvote_ratio,\n",
    "                    'num_comments': submission.num_comments,\n",
    "                    'text': submission.selftext,\n",
    "                    'url': submission.url, # URL the post links to (if not self-post)\n",
    "                    'permalink': f\"https://www.reddit.com{submission.permalink}\",\n",
    "                    'parent_id': None, # Posts don't have a parent in this context\n",
    "                    'parent_author': None\n",
    "                })\n",
    "\n",
    "                # Fetch comments for this post\n",
    "                submission.comments.replace_more(limit=5) # Expand top-level \"more comments\" links a few times\n",
    "                comment_count = 0\n",
    "                for comment in submission.comments.list():\n",
    "                    if comment_limit_per_post is not None and comment_count >= comment_limit_per_post:\n",
    "                        break\n",
    "                    comment_count += 1\n",
    "\n",
    "                    # Find parent author (can be post author or another comment author)\n",
    "                    parent_author = \"[deleted]\" # Default\n",
    "                    parent_is_post = comment.parent_id.startswith('t3_')\n",
    "                    if parent_is_post:\n",
    "                         parent_author = post_author\n",
    "                    else: # Parent is another comment (t1_)\n",
    "                        try:\n",
    "                            # Attempt to fetch parent comment directly (might fail if deleted)\n",
    "                            parent_comment = reddit.comment(comment.parent_id.split('_')[1])\n",
    "                            if parent_comment and parent_comment.author:\n",
    "                                parent_author = parent_comment.author.name\n",
    "                        except Exception:\n",
    "                             parent_author = \"[unknown_parent]\" # Or keep as deleted\n",
    "\n",
    "                    # Store comment data\n",
    "                    comment_author = comment.author.name if comment.author else \"[deleted]\"\n",
    "                    all_data.append({\n",
    "                        'type': 'comment',\n",
    "                        'id': comment.id,\n",
    "                        'subreddit': sub_name,\n",
    "                        'title': None, # Comments don't have titles\n",
    "                        'author': comment_author,\n",
    "                        'created_utc': comment.created_utc,\n",
    "                        'score': comment.score,\n",
    "                        'upvote_ratio': None, # Comments don't have upvote ratio\n",
    "                        'num_comments': None, # Not applicable directly\n",
    "                        'text': comment.body,\n",
    "                        'url': None, # Comments don't link to external URLs directly\n",
    "                        'permalink': f\"https://www.reddit.com{comment.permalink}\",\n",
    "                        'parent_id': comment.parent_id, # ID of the parent (post or comment)\n",
    "                        'parent_author': parent_author\n",
    "                    })\n",
    "\n",
    "                print(f\"    Fetched {comment_count} comments for post {submission.id}\")\n",
    "                time.sleep(1) # Be 'polite' to Reddit API between posts\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing subreddit r/{sub_name}: {e}\")\n",
    "        time.sleep(2) # Be extra polite between subreddits\n",
    "\n",
    "    # --- Convert to DataFrame and Save ---\n",
    "    if all_data:\n",
    "        df = pd.DataFrame(all_data)\n",
    "        # Convert UTC timestamp to datetime objects\n",
    "        df['created_datetime'] = pd.to_datetime(df['created_utc'], unit='s')\n",
    "        # Define output filename\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        output_filename = f\"reddit_data_{search_query.replace(' ','_')}_{timestamp}.csv\"\n",
    "        df.to_csv(output_filename, index=False)\n",
    "        print(f\"\\nData collection complete. Saved {len(df)} rows to {output_filename}\")\n",
    "    else:\n",
    "        print(\"\\nNo data collected.\")\n",
    "\n",
    "else:\n",
    "    print(\"Reddit instance not available. Scraping aborted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Identifying Evidence Indicators\n",
    "\n",
    "Instead of attempting full argument annotation, which is complex, I focused on identifying *indicators* that a user might be referencing external material.\n",
    "\n",
    "1.  **Indicator Identification**\n",
    "    *   I processed the `text` field of each post and comment in the DataFrame.\n",
    "    *   **URLs:** Regular expressions (`regex`) were used to detect and extract any HTTP/HTTPS links present in the text. A boolean flag (`has_url`) was added.\n",
    "    *   **Keywords:** A predefined list of words often associated with citing evidence (e.g., 'study', 'article', 'source', 'data', 'link') was compiled. Text was checked for the presence of these keywords (case-insensitive), resulting in a boolean flag (`has_keyword`).\n",
    "    *   **Combined Indicator:** A final boolean column (`has_evidence_indicator`) was created, marking rows that contained *either* a URL or an evidence-related keyword.\n",
    "\n",
    "2.  **Identifying Potential Contradictory Usage**\n",
    "    *   To find instances where the same evidence might be used differently, I extracted all unique URLs cited across the dataset.\n",
    "    *   I identified URLs that appeared more than once. These represent potential cases for RQ3, where multiple users referenced the same external source.\n",
    "\n",
    "3.  **Augmented Data Storage**\n",
    "    *   This indicator information was added to the DataFrame, which was then saved to a new CSV file (`..._augmented.csv`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Argument/Evidence Identification...\n",
      "Loaded data from reddit_data_Elon_Musk_20250408_011357.csv (4757 rows)\n",
      "\n",
      "Evidence Identification Summary:\n",
      "Rows with URLs: 194 (4.1%)\n",
      "Rows with Keywords: 172 (3.6%)\n",
      "Rows with any Evidence Indicator: 344 (7.2%)\n",
      "\n",
      "Found 3 unique URLs cited more than once.\n",
      "Top 5 most frequently cited URLs:\n",
      "urls_found\n",
      "https://elonmusk.today/                                    2\n",
      "https://www.reddit.com/r/PresidentElonMusk/s/LPoNoGq9Nx    2\n",
      "https://www.reddit.com/r/gifs/s/Vxk2zfwmpG)                2\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved augmented data with evidence indicators to reddit_data_Elon_Musk_20250408_011357_augmented.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arro1\\AppData\\Local\\Temp\\ipykernel_35632\\3296336121.py:47: UserWarning: This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.\n",
      "  df['has_keyword'] = df['text'].str.contains(keyword_pattern, case=False, regex=True, na=False)\n"
     ]
    }
   ],
   "source": [
    "# 5.2.1 Argument Annotation Code\n",
    "\n",
    "import pandas as pd\n",
    "import re # For regular expressions (finding URLs)\n",
    "\n",
    "print(\"Starting Argument/Evidence Identification...\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load the previously saved data\n",
    "# Adjust filename if you saved it differently or ran collection earlier\n",
    "input_filename = output_filename # Uses the filename saved from the previous step\n",
    "\n",
    "\n",
    "# Keywords that might indicate citing evidence \n",
    "evidence_keywords = ['study', 'research', 'data', 'stat', 'article', 'report',\n",
    "                     'source', 'evidence', 'according to', 'shows that', 'link', 'graph', 'chart']\n",
    "keyword_pattern = r'\\b(' + '|'.join(evidence_keywords) + r')\\b' # Regex for whole words\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    df = pd.read_csv(input_filename)\n",
    "    print(f\"Loaded data from {input_filename} ({len(df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {input_filename}. Make sure the data collection step ran successfully.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df = None\n",
    "\n",
    "# --- Identify Evidence ---\n",
    "if df is not None:\n",
    "    # Ensure 'text' column exists and handle potential NaN values\n",
    "    if 'text' in df.columns:\n",
    "        df['text'] = df['text'].fillna('') # Replace NaN with empty string\n",
    "    else:\n",
    "        print(\"Error: 'text' column not found in DataFrame.\")\n",
    "        df = None # Stop processing if text column is missing\n",
    "\n",
    "if df is not None:\n",
    "    # 1. Find URLs using regex\n",
    "    # Simple regex for URLs (might not catch all edge cases but good start)\n",
    "    url_pattern = r'https?://[^\\s/$.?#].[^\\s]*'\n",
    "    df['urls_found'] = df['text'].apply(lambda x: re.findall(url_pattern, str(x)))\n",
    "    df['has_url'] = df['urls_found'].apply(lambda x: len(x) > 0)\n",
    "\n",
    "    # 2. Find evidence-related keywords (case-insensitive)\n",
    "    df['has_keyword'] = df['text'].str.contains(keyword_pattern, case=False, regex=True, na=False)\n",
    "\n",
    "    # 3. Combine: Does it have either a URL or a keyword?\n",
    "    df['has_evidence_indicator'] = df['has_url'] | df['has_keyword']\n",
    "\n",
    "    # --- Summarize Findings ---\n",
    "    print(\"\\nEvidence Identification Summary:\")\n",
    "    print(f\"Rows with URLs: {df['has_url'].sum()} ({df['has_url'].mean()*100:.1f}%)\")\n",
    "    print(f\"Rows with Keywords: {df['has_keyword'].sum()} ({df['has_keyword'].mean()*100:.1f}%)\")\n",
    "    print(f\"Rows with any Evidence Indicator: {df['has_evidence_indicator'].sum()} ({df['has_evidence_indicator'].mean()*100:.1f}%)\")\n",
    "\n",
    "    # Identify potential contradictory usage (simple check: same URL used multiple times)\n",
    "    all_urls = df[df['has_url']]['urls_found'].explode() # Get a Series of all individual URLs found\n",
    "    if not all_urls.empty:\n",
    "        url_counts = all_urls.value_counts()\n",
    "        repeated_urls = url_counts[url_counts > 1]\n",
    "        print(f\"\\nFound {len(repeated_urls)} unique URLs cited more than once.\")\n",
    "        print(\"Top 5 most frequently cited URLs:\")\n",
    "        print(repeated_urls.head(5))\n",
    "        # You can further analyze posts/comments citing these specific URLs later\n",
    "\n",
    "    # --- Save Augmented Data ---\n",
    "    augmented_filename = input_filename.replace(\".csv\", \"_augmented.csv\")\n",
    "    df.to_csv(augmented_filename, index=False)\n",
    "    print(f\"\\nSaved augmented data with evidence indicators to {augmented_filename}\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame not available. Evidence identification aborted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Structuring the Conversation: Preparing Network Data for Gephi\n",
    "\n",
    "To visualize the underlying structure of the conversations and map how users interact, I transformed the collected data into a format suitable for network analysis using **Gephi**. This involves defining who the participants are (nodes) and how they connect (edges).\n",
    "\n",
    "1.  **Defining Nodes and Their Characteristics**\n",
    "    *   Each unique Redditor who authored a post or comment in the dataset became a **node** in the network. Users identified only as `[deleted]` or other placeholders were excluded.\n",
    "    *   Crucially, I aggregated key information for each author to serve as node attributes. Beyond basic activity metrics (post/comment counts, total/average scores, `used_evidence` count), I calculated the user's average VADER sentiment score (`avg_vader_sentiment`) and determined their most frequent stance towards Elon Musk (`dominant_openai_stance`) based on the OpenAI classifications of their comments. This enrichment allows for visualizing not just activity, but also attitude and stance directly onto the network participants.\n",
    "\n",
    "2.  **Mapping Interactions as Edges**\n",
    "    *   **Edges** represent direct replies between users. A directed edge was created from the author of a replying comment (`Source`) to the author of the parent comment or post (`Target`).\n",
    "    *   Edge attributes capture details about the reply itself, including the original comment's score, whether the reply contained an evidence indicator (`reply_has_evidence`), and importantly, the specific VADER sentiment (`reply_vader_sentiment`) and OpenAI stance (`reply_openai_stance`) of that particular replying comment. This allows for analyzing the nature of specific interactions.\n",
    "\n",
    "3.  **Export for Visualization**\n",
    "    *   The resulting node and edge lists, complete with their respective attributes (including the aggregated stance/sentiment for nodes and specific stance/sentiment for edges), were exported as two distinct CSV files (`gephi_nodes_..._final_...csv`, `gephi_edges_..._final_...csv`). These files are directly importable into Gephi.\n",
    "\n",
    "4.  **Visualization Goals with Enriched Data**\n",
    "    *   My aim in Gephi is to move beyond just seeing who talks to whom. By mapping attributes like `dominant_openai_stance` and `avg_vader_sentiment` onto the nodes (e.g., using color), and potentially filtering edges based on `reply_openai_stance`, I can explore:\n",
    "        *   Whether users with similar stances cluster together.\n",
    "        *   How users with different sentiments interact.\n",
    "        *   The structural position of users who frequently use evidence indicators, and how this relates to their stance.\n",
    "        *   Differences in interaction patterns and stance distributions between `r/technology` and `r/EnoughMuskSpam`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for Gephi (including Sentiment/Stance)...\n",
      "Loaded final analysis data from reddit_data_Elon_Musk_20250408_011357_final_analysis.csv (4757 rows)\n",
      "Aggregating user attributes (activity, sentiment, stance)...\n",
      "Creating Node list...\n",
      "Creating Edge list...\n",
      "\n",
      "Gephi data prepared (including aggregated stance/sentiment):\n",
      "  - Nodes (2875): gephi_nodes_Elon_Musk_final_20250408_024555.csv\n",
      "  - Edges (4550): gephi_edges_Elon_Musk_final_20250408_024555.csv\n",
      "Import these NEW CSV files into Gephi.\n"
     ]
    }
   ],
   "source": [
    "# 5.3.1 Export for Gephi (Updated to include Sentiment/Stance)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Preparing data for Gephi (including Sentiment/Stance)...\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load the FINAL data which includes sentiment and stance\n",
    "# Make sure this filename matches the output of cell 5.4.1\n",
    "input_filename = final_filename # Use the variable holding the final filename\n",
    "# Or uncomment and set manually:\n",
    "# input_filename = \"reddit_data_Elon_Musk_YYYYMMDD_HHMMSS_final_analysis.csv\"\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    df = pd.read_csv(input_filename)\n",
    "    # Ensure required columns exist and handle potential NaN in text/authors\n",
    "    df['text'] = df['text'].astype(str).fillna('')\n",
    "    df['author'] = df['author'].fillna('[deleted]')\n",
    "    df['parent_author'] = df['parent_author'].fillna('[deleted]') # Use a consistent placeholder\n",
    "    print(f\"Loaded final analysis data from {input_filename} ({len(df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {input_filename}. Make sure step 5.4.1 ran successfully and saved the file.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df = None\n",
    "\n",
    "# --- Create Nodes and Edges ---\n",
    "if df is not None:\n",
    "    # --- Aggregate User-Level Attributes ---\n",
    "    print(\"Aggregating user attributes (activity, sentiment, stance)...\")\n",
    "\n",
    "        # Define a function to get the mode (most frequent value) safely using pandas .mode()\n",
    "    def safe_mode(series):\n",
    "        # Exclude known non-user placeholders if necessary before calculating mode\n",
    "        # Also filter out generic/uninformative stances if you don't want them as dominant\n",
    "        valid_series = series.dropna()[~series.isin(['[deleted]', '[unknown_parent]', 'API Error', 'Processing Error', 'Unclear'])]\n",
    "        if valid_series.empty:\n",
    "            # Default stance if no valid ones are found for a user\n",
    "            # Choose what makes sense: 'Unknown', 'Neutral/Mixed', etc.\n",
    "            return 'Unknown'\n",
    "        else:\n",
    "            # .mode() returns a Series (can have multiple modes if tied)\n",
    "            # We usually just take the first one.\n",
    "            mode_result = valid_series.mode()\n",
    "            if not mode_result.empty:\n",
    "                return mode_result[0]\n",
    "            else:\n",
    "                # Should not happen if valid_series wasn't empty, but as a fallback\n",
    "                return 'Unknown'\n",
    "\n",
    "\n",
    "    author_stats = df[df['author'] != '[deleted]'].groupby('author').agg(\n",
    "        post_count=('type', lambda x: (x == 'post').sum()),\n",
    "        comment_count=('type', lambda x: (x == 'comment').sum()),\n",
    "        avg_score=('score', 'mean'),\n",
    "        total_score=('score', 'sum'),\n",
    "        used_evidence=('has_evidence_indicator', 'sum'),\n",
    "        # Aggregate sentiment and stance\n",
    "        avg_vader_sentiment=('vader_sentiment_compound', 'mean'),\n",
    "        dominant_openai_stance=('openai_stance', safe_mode) # Use the safe mode function\n",
    "    ).reset_index()\n",
    "\n",
    "    # --- Create Node List ---\n",
    "    print(\"Creating Node list...\")\n",
    "    # Nodes are unique authors (excluding deleted) from both author and parent_author columns\n",
    "    authors = pd.concat([df['author'], df['parent_author']]).unique()\n",
    "    nodes_df = pd.DataFrame(authors, columns=['Id'])\n",
    "    nodes_df = nodes_df[~nodes_df['Id'].isin(['[deleted]', '[unknown_parent]'])] # Remove known placeholders\n",
    "\n",
    "    nodes_df['Label'] = nodes_df['Id'] # Gephi uses 'Label' column for text display\n",
    "\n",
    "    # Merge aggregated stats\n",
    "    nodes_df = pd.merge(nodes_df, author_stats, left_on='Id', right_on='author', how='left')\n",
    "    nodes_df = nodes_df.drop(columns=['author']) # Remove redundant column\n",
    "    # Fill NaNs for users who only received replies (didn't post/comment themselves in the sample)\n",
    "    # Fill numerical NaNs with 0, categorical NaNs with a default like 'Unknown' or 'Neutral/Mixed'\n",
    "    numeric_cols = ['post_count', 'comment_count', 'avg_score', 'total_score', 'used_evidence', 'avg_vader_sentiment']\n",
    "    for col in numeric_cols:\n",
    "        if col in nodes_df.columns:\n",
    "            nodes_df[col] = nodes_df[col].fillna(0)\n",
    "    if 'dominant_openai_stance' in nodes_df.columns:\n",
    "         nodes_df['dominant_openai_stance'] = nodes_df['dominant_openai_stance'].fillna('Unknown') # Handle users with no classifiable comments\n",
    "\n",
    "\n",
    "    # --- Create Edge List ---\n",
    "    print(\"Creating Edge list...\")\n",
    "    # Edges represent replies (comment author -> parent author)\n",
    "    # Filter for comments that have valid source and target authors\n",
    "    edges_df = df[\n",
    "        (df['type'] == 'comment') &\n",
    "        (~df['author'].isin(['[deleted]', '[unknown_parent]'])) & # Valid source\n",
    "        (df['parent_author'].notna()) &\n",
    "        (~df['parent_author'].isin(['[deleted]', '[unknown_parent]'])) # Valid target\n",
    "    ].copy() # Make a copy to avoid SettingWithCopyWarning\n",
    "\n",
    "    # Select and rename columns for Gephi edge format\n",
    "    edges_df = edges_df[['author', 'parent_author', 'score', 'has_evidence_indicator', 'vader_sentiment_compound', 'openai_stance', 'id']] # Keep comment id for potential reference\n",
    "    edges_df.rename(columns={\n",
    "        'author': 'Source',\n",
    "        'parent_author': 'Target',\n",
    "        'score': 'comment_score', # Rename to avoid clash with node scores\n",
    "        'has_evidence_indicator': 'reply_has_evidence',\n",
    "        'vader_sentiment_compound': 'reply_vader_sentiment',\n",
    "        'openai_stance': 'reply_openai_stance',\n",
    "        'id': 'comment_id'\n",
    "        }, inplace=True)\n",
    "\n",
    "    edges_df['Type'] = 'Directed' # Edges go from replier to parent\n",
    "    edges_df['Weight'] = 1.0 # Default weight for each reply\n",
    "\n",
    "\n",
    "    # --- Save Files ---\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\") # Add timestamp to avoid overwriting old files\n",
    "    nodes_filename = f\"gephi_nodes_{search_query.replace(' ','_')}_final_{timestamp}.csv\"\n",
    "    edges_filename = f\"gephi_edges_{search_query.replace(' ','_')}_final_{timestamp}.csv\"\n",
    "\n",
    "    nodes_df.to_csv(nodes_filename, index=False)\n",
    "    edges_df.to_csv(edges_filename, index=False)\n",
    "\n",
    "    print(f\"\\nGephi data prepared (including aggregated stance/sentiment):\")\n",
    "    print(f\"  - Nodes ({len(nodes_df)}): {nodes_filename}\")\n",
    "    print(f\"  - Edges ({len(edges_df)}): {edges_filename}\")\n",
    "    print(\"Import these NEW CSV files into Gephi.\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame not available. Gephi export aborted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Sentiment Analysis (VADER) and Stance Detection (OpenAI)\n",
    "\n",
    "To gauge the emotional tone and the specific alignment of the discussions towards Elon Musk, I employed two distinct computational methods:\n",
    "\n",
    "1.  **Sentiment Analysis Tool (VADER)**\n",
    "    *   I used **VADER (Valence Aware Dictionary and sEntiment Reasoner)**, a lexicon and rule-based sentiment analysis tool attuned to social media language.\n",
    "    *   VADER provided a `compound` score from -1 (most negative) to +1 (most positive) for each post and comment, capturing the overall emotional polarity. This was stored in the `vader_sentiment_compound` column.\n",
    "\n",
    "2.  **Stance Detection Tool (OpenAI GPT)**\n",
    "    *   To understand *how* users were positioned relative to Elon Musk (beyond just positive/negative tone), I utilized OpenAI's **GPT model (specifically `gpt-3.5-turbo` in this run)**.\n",
    "    *   I crafted a prompt asking the model to classify the stance of each post/comment into predefined categories: `\"Pro-Musk\"`, `\"Anti-Musk\"`, `\"Neutral/Mixed\"`, or `\"Unclear\"`.\n",
    "    *   The text from each post/comment was sent in batches to the OpenAI API. The model's classification for each item was parsed from the response.\n",
    "    *   This classification, representing the inferred authorial stance towards Musk, was stored in the `openai_stance` column. *Initial results show classifications like \"Anti-Musk\" for critical comments (e.g., \"What a hypocrite this dude is.\") and \"Neutral/Mixed\" or \"Unclear\" for others, demonstrating the model's ability to differentiate.*\n",
    "\n",
    "3.  **Combined Analysis Approach**\n",
    "    *   Having both VADER sentiment and OpenAI stance allows for a more nuanced understanding. For example, a comment could have negative sentiment (VADER score < 0) and be classified as \"Anti-Musk\" (OpenAI stance), confirming strong criticism. Conversely, a comment might be neutral in sentiment (VADER score ≈ 0) but still classified as \"Pro-Musk\" or \"Anti-Musk\" based on the content's alignment.\n",
    "\n",
    "4.  **Final Data Storage**\n",
    "    *   The DataFrame, now augmented with evidence indicators, VADER sentiment scores, and OpenAI stance classifications, was saved to a final CSV file (`..._final_analysis.csv`). This comprehensive dataset serves as the foundation for the subsequent discussion and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Sentiment/Stance Analysis...\n",
      "Loaded data from reddit_data_Elon_Musk_20250408_011357_augmented.csv (4757 rows)\n",
      "\n",
      "--- Running VADER Sentiment Analysis ---\n",
      "VADER analysis complete. Added 'vader_sentiment_compound' column.\n",
      "Sentiment Score Summary:\n",
      "count    4757.000000\n",
      "mean       -0.037494\n",
      "std         0.470868\n",
      "min        -0.987900\n",
      "25%        -0.421500\n",
      "50%         0.000000\n",
      "75%         0.335500\n",
      "max         0.995500\n",
      "Name: vader_sentiment_compound, dtype: float64\n",
      "\n",
      "--- Preparing for OpenAI Stance Detection\n",
      "OpenAI client initialized.\n",
      "\n",
      "--- Running OpenAI Stance Detection (this may take time and cost money) ---\n",
      "  Processed batch 1/476\n",
      "  Processed batch 2/476\n",
      "  Processed batch 3/476\n",
      "  Processed batch 4/476\n",
      "  Processed batch 5/476\n",
      "  Processed batch 6/476\n",
      "  Processed batch 7/476\n",
      "  Processed batch 8/476\n",
      "  Processed batch 9/476\n",
      "  Processed batch 10/476\n",
      "  Processed batch 11/476\n",
      "  Processed batch 12/476\n",
      "  Processed batch 13/476\n",
      "  Processed batch 14/476\n",
      "  Processed batch 15/476\n",
      "  Processed batch 16/476\n",
      "  Processed batch 17/476\n",
      "  Processed batch 18/476\n",
      "  Processed batch 19/476\n",
      "  Processed batch 20/476\n",
      "  Processed batch 21/476\n",
      "  Processed batch 22/476\n",
      "  Processed batch 23/476\n",
      "  Processed batch 24/476\n",
      "  Processed batch 25/476\n",
      "  Processed batch 26/476\n",
      "  Processed batch 27/476\n",
      "  Processed batch 28/476\n",
      "  Processed batch 29/476\n",
      "  Processed batch 30/476\n",
      "  Processed batch 31/476\n",
      "  Processed batch 32/476\n",
      "  Processed batch 33/476\n",
      "  Processed batch 34/476\n",
      "  Processed batch 35/476\n",
      "  Processed batch 36/476\n",
      "  Processed batch 37/476\n",
      "  Processed batch 38/476\n",
      "  Processed batch 39/476\n",
      "  Processed batch 40/476\n",
      "  Processed batch 41/476\n",
      "  Processed batch 42/476\n",
      "  Processed batch 43/476\n",
      "  Processed batch 44/476\n",
      "  Processed batch 45/476\n",
      "  Processed batch 46/476\n",
      "  Processed batch 47/476\n",
      "  Processed batch 48/476\n",
      "  Processed batch 49/476\n",
      "  Processed batch 50/476\n",
      "  Processed batch 51/476\n",
      "  Processed batch 52/476\n",
      "  Processed batch 53/476\n",
      "  Processed batch 54/476\n",
      "  Processed batch 55/476\n",
      "  Processed batch 56/476\n",
      "  Processed batch 57/476\n",
      "  Processed batch 58/476\n",
      "  Processed batch 59/476\n",
      "  Processed batch 60/476\n",
      "  Processed batch 61/476\n",
      "  Processed batch 62/476\n",
      "  Processed batch 63/476\n",
      "  Processed batch 64/476\n",
      "  Processed batch 65/476\n",
      "  Processed batch 66/476\n",
      "  Processed batch 67/476\n",
      "  Processed batch 68/476\n",
      "  Processed batch 69/476\n",
      "  Processed batch 70/476\n",
      "  Processed batch 71/476\n",
      "  Processed batch 72/476\n",
      "  Processed batch 73/476\n",
      "  Processed batch 74/476\n",
      "  Processed batch 75/476\n",
      "  Processed batch 76/476\n",
      "  Processed batch 77/476\n",
      "  Processed batch 78/476\n",
      "  Processed batch 79/476\n",
      "  Processed batch 80/476\n",
      "  Processed batch 81/476\n",
      "  Processed batch 82/476\n",
      "  Processed batch 83/476\n",
      "  Processed batch 84/476\n",
      "  Processed batch 85/476\n",
      "  Processed batch 86/476\n",
      "  Processed batch 87/476\n",
      "  Processed batch 88/476\n",
      "  Processed batch 89/476\n",
      "  Processed batch 90/476\n",
      "  Processed batch 91/476\n",
      "  Processed batch 92/476\n",
      "  Processed batch 93/476\n",
      "  Processed batch 94/476\n",
      "  Processed batch 95/476\n",
      "  Processed batch 96/476\n",
      "  Processed batch 97/476\n",
      "  Processed batch 98/476\n",
      "  Processed batch 99/476\n",
      "  Processed batch 100/476\n",
      "  Processed batch 101/476\n",
      "  Processed batch 102/476\n",
      "  Processed batch 103/476\n",
      "  Processed batch 104/476\n",
      "  Processed batch 105/476\n",
      "  Processed batch 106/476\n",
      "  Processed batch 107/476\n",
      "  Processed batch 108/476\n",
      "  Processed batch 109/476\n",
      "  Processed batch 110/476\n",
      "  Processed batch 111/476\n",
      "  Processed batch 112/476\n",
      "  Processed batch 113/476\n",
      "  Processed batch 114/476\n",
      "  Processed batch 115/476\n",
      "  Processed batch 116/476\n",
      "  Processed batch 117/476\n",
      "  Processed batch 118/476\n",
      "  Processed batch 119/476\n",
      "  Processed batch 120/476\n",
      "  Processed batch 121/476\n",
      "  Processed batch 122/476\n",
      "  Processed batch 123/476\n",
      "  Processed batch 124/476\n",
      "  Processed batch 125/476\n",
      "  Processed batch 126/476\n",
      "  Processed batch 127/476\n",
      "  Processed batch 128/476\n",
      "  Processed batch 129/476\n",
      "  Processed batch 130/476\n",
      "  Processed batch 131/476\n",
      "  Processed batch 132/476\n",
      "  Processed batch 133/476\n",
      "  Processed batch 134/476\n",
      "  Processed batch 135/476\n",
      "  Processed batch 136/476\n",
      "  Processed batch 137/476\n",
      "  Processed batch 138/476\n",
      "  Processed batch 139/476\n",
      "  Processed batch 140/476\n",
      "  Processed batch 141/476\n",
      "  Processed batch 142/476\n",
      "  Processed batch 143/476\n",
      "  Processed batch 144/476\n",
      "  Processed batch 145/476\n",
      "  Processed batch 146/476\n",
      "  Processed batch 147/476\n",
      "  Processed batch 148/476\n",
      "  Processed batch 149/476\n",
      "  Processed batch 150/476\n",
      "  Processed batch 151/476\n",
      "  Processed batch 152/476\n",
      "  Processed batch 153/476\n",
      "  Processed batch 154/476\n",
      "  Processed batch 155/476\n",
      "  Processed batch 156/476\n",
      "  Processed batch 157/476\n",
      "  Processed batch 158/476\n",
      "  Processed batch 159/476\n",
      "  Processed batch 160/476\n",
      "  Processed batch 161/476\n",
      "  Processed batch 162/476\n",
      "  Processed batch 163/476\n",
      "  Processed batch 164/476\n",
      "  Processed batch 165/476\n",
      "  Processed batch 166/476\n",
      "  Processed batch 167/476\n",
      "  Processed batch 168/476\n",
      "  Processed batch 169/476\n",
      "  Processed batch 170/476\n",
      "  Processed batch 171/476\n",
      "  Processed batch 172/476\n",
      "  Processed batch 173/476\n",
      "  Processed batch 174/476\n",
      "  Processed batch 175/476\n",
      "  Processed batch 176/476\n",
      "  Processed batch 177/476\n",
      "  Processed batch 178/476\n",
      "  Processed batch 179/476\n",
      "  Processed batch 180/476\n",
      "  Processed batch 181/476\n",
      "  Processed batch 182/476\n",
      "  Processed batch 183/476\n",
      "  Processed batch 184/476\n",
      "  Processed batch 185/476\n",
      "  Processed batch 186/476\n",
      "  Processed batch 187/476\n",
      "  Processed batch 188/476\n",
      "  Processed batch 189/476\n",
      "  Processed batch 190/476\n",
      "  Processed batch 191/476\n",
      "  Processed batch 192/476\n",
      "  Processed batch 193/476\n",
      "  Processed batch 194/476\n",
      "  Processed batch 195/476\n",
      "  Processed batch 196/476\n",
      "  Processed batch 197/476\n",
      "  Processed batch 198/476\n",
      "  Processed batch 199/476\n",
      "  Processed batch 200/476\n",
      "  Processed batch 201/476\n",
      "  Processed batch 202/476\n",
      "  Processed batch 203/476\n",
      "  Processed batch 204/476\n",
      "  Processed batch 205/476\n",
      "  Processed batch 206/476\n",
      "  Processed batch 207/476\n",
      "  Processed batch 208/476\n",
      "  Processed batch 209/476\n",
      "  Processed batch 210/476\n",
      "  Processed batch 211/476\n",
      "  Processed batch 212/476\n",
      "  Processed batch 213/476\n",
      "  Processed batch 214/476\n",
      "  Processed batch 215/476\n",
      "  Processed batch 216/476\n",
      "  Processed batch 217/476\n",
      "  Processed batch 218/476\n",
      "  Processed batch 219/476\n",
      "  Processed batch 220/476\n",
      "  Processed batch 221/476\n",
      "  Processed batch 222/476\n",
      "  Processed batch 223/476\n",
      "  Processed batch 224/476\n",
      "  Processed batch 225/476\n",
      "  Processed batch 226/476\n",
      "  Processed batch 227/476\n",
      "  Processed batch 228/476\n",
      "  Processed batch 229/476\n",
      "  Processed batch 230/476\n",
      "  Processed batch 231/476\n",
      "  Processed batch 232/476\n",
      "  Processed batch 233/476\n",
      "  Processed batch 234/476\n",
      "  Processed batch 235/476\n",
      "  Processed batch 236/476\n",
      "  Processed batch 237/476\n",
      "  Processed batch 238/476\n",
      "  Processed batch 239/476\n",
      "  Processed batch 240/476\n",
      "  Processed batch 241/476\n",
      "  Processed batch 242/476\n",
      "  Processed batch 243/476\n",
      "  Processed batch 244/476\n",
      "  Processed batch 245/476\n",
      "  Processed batch 246/476\n",
      "  Processed batch 247/476\n",
      "  Processed batch 248/476\n",
      "  Processed batch 249/476\n",
      "  Processed batch 250/476\n",
      "  Processed batch 251/476\n",
      "  Processed batch 252/476\n",
      "  Processed batch 253/476\n",
      "  Processed batch 254/476\n",
      "  Processed batch 255/476\n",
      "  Processed batch 256/476\n",
      "  Processed batch 257/476\n",
      "  Processed batch 258/476\n",
      "  Processed batch 259/476\n",
      "  Processed batch 260/476\n",
      "  Processed batch 261/476\n",
      "  Processed batch 262/476\n",
      "  Processed batch 263/476\n",
      "  Processed batch 264/476\n",
      "  Processed batch 265/476\n",
      "  Processed batch 266/476\n",
      "  Processed batch 267/476\n",
      "  Processed batch 268/476\n",
      "  Processed batch 269/476\n",
      "  Processed batch 270/476\n",
      "  Processed batch 271/476\n",
      "  Processed batch 272/476\n",
      "  Processed batch 273/476\n",
      "  Processed batch 274/476\n",
      "  Processed batch 275/476\n",
      "  Processed batch 276/476\n",
      "  Processed batch 277/476\n",
      "  Processed batch 278/476\n",
      "  Processed batch 279/476\n",
      "  Processed batch 280/476\n",
      "  Processed batch 281/476\n",
      "  Processed batch 282/476\n",
      "  Processed batch 283/476\n",
      "  Processed batch 284/476\n",
      "  Processed batch 285/476\n",
      "  Processed batch 286/476\n",
      "  Processed batch 287/476\n",
      "  Processed batch 288/476\n",
      "  Processed batch 289/476\n",
      "  Processed batch 290/476\n",
      "  Processed batch 291/476\n",
      "  Processed batch 292/476\n",
      "  Processed batch 293/476\n",
      "  Processed batch 294/476\n",
      "  Processed batch 295/476\n",
      "  Processed batch 296/476\n",
      "  Processed batch 297/476\n",
      "  Processed batch 298/476\n",
      "  Processed batch 299/476\n",
      "  Processed batch 300/476\n",
      "  Processed batch 301/476\n",
      "  Processed batch 302/476\n",
      "  Processed batch 303/476\n",
      "  Processed batch 304/476\n",
      "  Processed batch 305/476\n",
      "  Processed batch 306/476\n",
      "  Processed batch 307/476\n",
      "  Processed batch 308/476\n",
      "  Processed batch 309/476\n",
      "  Processed batch 310/476\n",
      "  Processed batch 311/476\n",
      "  Processed batch 312/476\n",
      "  Processed batch 313/476\n",
      "  Processed batch 314/476\n",
      "  Processed batch 315/476\n",
      "  Processed batch 316/476\n",
      "  Processed batch 317/476\n",
      "  Processed batch 318/476\n",
      "  Processed batch 319/476\n",
      "  Processed batch 320/476\n",
      "  Processed batch 321/476\n",
      "  Processed batch 322/476\n",
      "  Processed batch 323/476\n",
      "  Processed batch 324/476\n",
      "  Processed batch 325/476\n",
      "  Processed batch 326/476\n",
      "  Processed batch 327/476\n",
      "  Processed batch 328/476\n",
      "  Processed batch 329/476\n",
      "  Processed batch 330/476\n",
      "  Processed batch 331/476\n",
      "  Processed batch 332/476\n",
      "  Processed batch 333/476\n",
      "  Processed batch 334/476\n",
      "  Processed batch 335/476\n",
      "  Processed batch 336/476\n",
      "  Processed batch 337/476\n",
      "  Processed batch 338/476\n",
      "  Processed batch 339/476\n",
      "  Processed batch 340/476\n",
      "  Processed batch 341/476\n",
      "  Processed batch 342/476\n",
      "  Processed batch 343/476\n",
      "  Processed batch 344/476\n",
      "  Processed batch 345/476\n",
      "  Processed batch 346/476\n",
      "  Processed batch 347/476\n",
      "  Processed batch 348/476\n",
      "  Processed batch 349/476\n",
      "  Processed batch 350/476\n",
      "  Processed batch 351/476\n",
      "  Processed batch 352/476\n",
      "  Processed batch 353/476\n",
      "  Processed batch 354/476\n",
      "  Processed batch 355/476\n",
      "  Processed batch 356/476\n",
      "  Processed batch 357/476\n",
      "  Processed batch 358/476\n",
      "  Processed batch 359/476\n",
      "  Processed batch 360/476\n",
      "  Processed batch 361/476\n",
      "  Processed batch 362/476\n",
      "  Processed batch 363/476\n",
      "  Processed batch 364/476\n",
      "  Processed batch 365/476\n",
      "  Processed batch 366/476\n",
      "  Processed batch 367/476\n",
      "  Processed batch 368/476\n",
      "  Processed batch 369/476\n",
      "  Processed batch 370/476\n",
      "  Processed batch 371/476\n",
      "  Processed batch 372/476\n",
      "  Processed batch 373/476\n",
      "  Processed batch 374/476\n",
      "  Processed batch 375/476\n",
      "  Processed batch 376/476\n",
      "  Processed batch 377/476\n",
      "  Processed batch 378/476\n",
      "  Processed batch 379/476\n",
      "  Processed batch 380/476\n",
      "  Processed batch 381/476\n",
      "  Processed batch 382/476\n",
      "  Processed batch 383/476\n",
      "  Processed batch 384/476\n",
      "  Processed batch 385/476\n",
      "  Processed batch 386/476\n",
      "  Processed batch 387/476\n",
      "  Processed batch 388/476\n",
      "  Processed batch 389/476\n",
      "  Processed batch 390/476\n",
      "  Processed batch 391/476\n",
      "  Processed batch 392/476\n",
      "  Processed batch 393/476\n",
      "  Processed batch 394/476\n",
      "  Processed batch 395/476\n",
      "  Processed batch 396/476\n",
      "  Processed batch 397/476\n",
      "  Processed batch 398/476\n",
      "  Processed batch 399/476\n",
      "  Processed batch 400/476\n",
      "  Processed batch 401/476\n",
      "  Processed batch 402/476\n",
      "  Processed batch 403/476\n",
      "  Processed batch 404/476\n",
      "  Processed batch 405/476\n",
      "  Processed batch 406/476\n",
      "  Processed batch 407/476\n",
      "  Processed batch 408/476\n",
      "  Processed batch 409/476\n",
      "  Processed batch 410/476\n",
      "  Processed batch 411/476\n",
      "  Processed batch 412/476\n",
      "  Processed batch 413/476\n",
      "  Processed batch 414/476\n",
      "  Processed batch 415/476\n",
      "  Processed batch 416/476\n",
      "  Processed batch 417/476\n",
      "  Processed batch 418/476\n",
      "  Processed batch 419/476\n",
      "  Processed batch 420/476\n",
      "  Processed batch 421/476\n",
      "  Processed batch 422/476\n",
      "  Processed batch 423/476\n",
      "  Processed batch 424/476\n",
      "  Processed batch 425/476\n",
      "  Processed batch 426/476\n",
      "  Processed batch 427/476\n",
      "  Processed batch 428/476\n",
      "  Processed batch 429/476\n",
      "  Processed batch 430/476\n",
      "  Processed batch 431/476\n",
      "  Processed batch 432/476\n",
      "  Processed batch 433/476\n",
      "  Processed batch 434/476\n",
      "  Processed batch 435/476\n",
      "  Processed batch 436/476\n",
      "  Processed batch 437/476\n",
      "  Processed batch 438/476\n",
      "  Processed batch 439/476\n",
      "  Processed batch 440/476\n",
      "  Processed batch 441/476\n",
      "  Processed batch 442/476\n",
      "  Processed batch 443/476\n",
      "  Processed batch 444/476\n",
      "  Processed batch 445/476\n",
      "  Processed batch 446/476\n",
      "  Processed batch 447/476\n",
      "  Processed batch 448/476\n",
      "  Processed batch 449/476\n",
      "  Processed batch 450/476\n",
      "  Processed batch 451/476\n",
      "  Processed batch 452/476\n",
      "  Processed batch 453/476\n",
      "  Processed batch 454/476\n",
      "  Processed batch 455/476\n",
      "  Processed batch 456/476\n",
      "  Processed batch 457/476\n",
      "  Processed batch 458/476\n",
      "  Processed batch 459/476\n",
      "  Processed batch 460/476\n",
      "  Processed batch 461/476\n",
      "  Processed batch 462/476\n",
      "  Processed batch 463/476\n",
      "  Processed batch 464/476\n",
      "  Processed batch 465/476\n",
      "  Processed batch 466/476\n",
      "  Processed batch 467/476\n",
      "  Processed batch 468/476\n",
      "  Processed batch 469/476\n",
      "  Processed batch 470/476\n",
      "  Processed batch 471/476\n",
      "  Processed batch 472/476\n",
      "  Processed batch 473/476\n",
      "  Processed batch 474/476\n",
      "  Processed batch 475/476\n",
      "  Processed batch 476/476\n",
      "OpenAI stance classification complete. Added 'openai_stance' column.\n",
      "Stance Distribution (OpenAI):\n",
      "openai_stance\n",
      "Unclear          3015\n",
      "Anti-Musk        1221\n",
      "Neutral/Mixed     415\n",
      "Pro-Musk          102\n",
      "Negative            4\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saved final data with sentiment/stance analysis to reddit_data_Elon_Musk_20250408_011357_final_analysis.csv\n"
     ]
    }
   ],
   "source": [
    "# 5.4.1 Sentiment / Stance Analysis Code\n",
    "\n",
    "import pandas as pd\n",
    "# Option 1: Simple Rule-Based Sentiment (VADER)\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Option 2: Advanced Stance/Sentiment \n",
    "import openai\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "\n",
    "print(\"Starting Sentiment/Stance Analysis...\")\n",
    "\n",
    "# --- Configuration ---\n",
    "# Load the augmented data\n",
    "input_filename = augmented_filename # From step 5.2.1\n",
    "\n",
    "\n",
    "# --- Load Data ---\n",
    "try:\n",
    "    df = pd.read_csv(input_filename)\n",
    "    # Ensure 'text' column is string and handle NaN\n",
    "    df['text'] = df['text'].astype(str).fillna('')\n",
    "    print(f\"Loaded data from {input_filename} ({len(df)} rows)\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Input file not found at {input_filename}.\")\n",
    "    df = None\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {e}\")\n",
    "    df = None\n",
    "\n",
    "# --- Option 1: VADER Sentiment Analysis ---\n",
    "if df is not None:\n",
    "    print(\"\\n--- Running VADER Sentiment Analysis ---\")\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    # Function to get VADER compound score\n",
    "    def get_vader_sentiment(text):\n",
    "        vs = analyzer.polarity_scores(text)\n",
    "        return vs['compound'] # Compound score ranges from -1 (most negative) to +1 (most positive)\n",
    "\n",
    "    # Apply VADER to the 'text' column (works for both posts and comments)\n",
    "\n",
    "    df['vader_sentiment_compound'] = df['text'].apply(get_vader_sentiment)\n",
    "\n",
    "    print(\"VADER analysis complete. Added 'vader_sentiment_compound' column.\")\n",
    "    print(\"Sentiment Score Summary:\")\n",
    "    print(df['vader_sentiment_compound'].describe())\n",
    "\n",
    "# --- Option 2: Stance Detection using OpenAI ---\n",
    "\n",
    "\n",
    "print(\"\\n--- Preparing for OpenAI Stance Detection\")\n",
    "# # --- OpenAI Setup ---\n",
    "try:\n",
    "    openai_api_key = os.environ.get(\"OPENAI_API_KEY\", \"YOUR_OPENAI_API_KEY\")\n",
    "    if not openai_api_key or openai_api_key == \"YOUR_OPENAI_API_KEY\":\n",
    "         print(\"Warning: OpenAI API Key not found or not set in environment variables.\")\n",
    "         openai_client = None\n",
    "    else:\n",
    "         openai_client = openai.OpenAI(api_key=openai_api_key)\n",
    "         print(\"OpenAI client initialized.\")\n",
    "except Exception as e:\n",
    "     print(f\"Error initializing OpenAI client: {e}\")\n",
    "     openai_client = None\n",
    "\n",
    " # Function to classify stance using OpenAI (modify prompt as needed)\n",
    "def classify_stance_openai(texts, batch_size=10):\n",
    "     if not openai_client or not texts:\n",
    "         return [\"Error: OpenAI not configured or no texts\"] * len(texts)\n",
    "\n",
    "     results = {} # Use dictionary to store results mapped to original index\n",
    "\n",
    "     for i in range(0, len(texts), batch_size):\n",
    "         batch_texts = texts[i : i + batch_size]\n",
    "         original_indices = list(range(i, i + len(batch_texts))) # Keep track of original index\n",
    "\n",
    "         classification_prompt = \"\"\n",
    "         for idx, text in enumerate(batch_texts):\n",
    "             cleaned_text = str(text).replace('\\n', ' ').replace('\"', \"'\") # Basic cleaning\n",
    "             classification_prompt += f'{idx}: \"{cleaned_text[:500]}\"\\n\\n' # Limit text length per item\n",
    "\n",
    "         system_prompt = f\"\"\"\n",
    "         You are analyzing Reddit comments about Elon Musk.\n",
    "         For each text provided (indexed from 0), determine the author's stance towards Elon Musk.\n",
    "         Classify the stance into one of these categories:\n",
    "         - \"Pro-Musk\": Clearly positive, supportive, defending Musk.\n",
    "         - \"Anti-Musk\": Clearly negative, critical, attacking Musk.\n",
    "         - \"Neutral/Mixed\": No clear stance, balanced, objective, or discussing tangentially.\n",
    "         - \"Unclear\": Cannot determine stance from the text provided.\n",
    "\n",
    "         Provide your response as a JSON object for each text on a new line. Example format:\n",
    "         {{\"Index\": 0, \"Stance\": \"Anti-Musk\"}}\n",
    "         {{\"Index\": 1, \"Stance\": \"Pro-Musk\"}}\n",
    "         \"\"\"\n",
    "\n",
    "         try:\n",
    "             response = openai_client.chat.completions.create(\n",
    "                 model=\"gpt-3.5-turbo\", # Or use \"gpt-4\" for potentially better (but slower/costlier) results\n",
    "                 messages=[\n",
    "                     {\"role\": \"system\", \"content\": system_prompt},\n",
    "                     {\"role\": \"user\", \"content\": f\"Classify the stance for these texts:\\n{classification_prompt}\"}\n",
    "                 ],\n",
    "                 temperature=0.2 # Lower temperature for more deterministic results\n",
    "             )\n",
    "             response_content = response.choices[0].message.content\n",
    "\n",
    "             # Parse the response (expecting JSON per line)\n",
    "             lines = response_content.strip().split('\\n')\n",
    "             for line in lines:\n",
    "                 try:\n",
    "                     data = json.loads(line.strip())\n",
    "                     batch_index = data.get(\"Index\")\n",
    "                     stance = data.get(\"Stance\")\n",
    "                     if batch_index is not None and stance is not None and 0 <= batch_index < len(original_indices):\n",
    "                         original_idx = original_indices[batch_index]\n",
    "                         results[original_idx] = stance\n",
    "                 except json.JSONDecodeError:\n",
    "                     print(f\"Warning: Could not decode JSON line: {line}\")\n",
    "                 except Exception as parse_e:\n",
    "                      print(f\"Warning: Error processing line '{line}': {parse_e}\")\n",
    "\n",
    "\n",
    "             print(f\"  Processed batch {i//batch_size + 1}/{(len(texts) + batch_size - 1)//batch_size}\")\n",
    "             time.sleep(1) # Rate limiting\n",
    "\n",
    "         except Exception as api_e:\n",
    "             print(f\"Error calling OpenAI API: {api_e}\")\n",
    "             # Mark remaining items in batch as error\n",
    "             for idx in original_indices:\n",
    "                 if idx not in results:\n",
    "                     results[idx] = \"API Error\"\n",
    "             time.sleep(5) # Wait longer after an API error\n",
    "\n",
    "     # Return stances in the original order\n",
    "     final_stances = [results.get(idx, \"Processing Error\") for idx in range(len(texts))]\n",
    "     return final_stances\n",
    "\n",
    "\n",
    " # --- Apply OpenAI Stance Classification (if configured) ---\n",
    "if df is not None and openai_client:\n",
    "     print(\"\\n--- Running OpenAI Stance Detection (this may take time and cost money) ---\")\n",
    "     # Select only comments for stance detection, or apply to all? Let's do all for simplicity here.\n",
    "     texts_to_classify = df['text'].tolist()\n",
    "     stances = classify_stance_openai(texts_to_classify)\n",
    "\n",
    "     if len(stances) == len(df):\n",
    "         df['openai_stance'] = stances\n",
    "         print(\"OpenAI stance classification complete. Added 'openai_stance' column.\")\n",
    "         print(\"Stance Distribution (OpenAI):\")\n",
    "         print(df['openai_stance'].value_counts())\n",
    "     else:\n",
    "         print(f\"Error: Number of stance results ({len(stances)}) does not match DataFrame rows ({len(df)}).\")\n",
    "elif df is not None:\n",
    "      print(\"\\n--- Skipping OpenAI Stance Detection (not configured or enabled) ---\")\n",
    "\n",
    "\n",
    "# --- Save Final Data ---\n",
    "if df is not None:\n",
    "    final_filename = input_filename.replace(\"_augmented.csv\", \"_final_analysis.csv\")\n",
    "    df.to_csv(final_filename, index=False)\n",
    "    print(f\"\\nSaved final data with sentiment/stance analysis to {final_filename}\")\n",
    "\n",
    "else:\n",
    "    print(\"DataFrame not available. Sentiment/stance analysis aborted.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Preliminary Discussion and Findings\n",
    "\n",
    "Having executed the data collection, evidence indicator identification, sentiment analysis (VADER), stance detection (OpenAI), and network data preparation, I can now discuss the key findings emerging from the analysis of discussions surrounding Elon Musk in `r/technology` and `r/EnoughMuskSpam`.\n",
    "\n",
    "**Stance Distribution:**\n",
    "\n",
    "The OpenAI stance classification revealed a distinct landscape of opinions. Across the 4785 analyzed posts and comments:\n",
    "*   A significant portion (**~54%**) were classified as **\"Unknown\"**. This could reflect limitations in the GPT-3.5 model's ability to interpret nuanced or short comments, or it might indicate that many comments genuinely didn't express a clear stance on Musk himself, perhaps focusing on tangential aspects of the news or discussion.\n",
    "*   Among the comments where a stance *was* detected, there was a strong skew towards negativity: **~34%** were classified as **\"Anti-Musk\"**.\n",
    "*   **\"Neutral/Mixed\"** stances accounted for **~9.6%**.\n",
    "*   Explicitly **\"Pro-Musk\"** stances were relatively rare, representing only **~2.3%** of the total.\n",
    "\n",
    "This distribution suggests that while overt support for Musk was minimal in these specific discussions and subreddits during the sampled period, outright criticism was common. The large \"Unknown\" category warrants further investigation, potentially through manual review or using a more advanced model, but the dominance of \"Anti-Musk\" among classified stances is a clear finding.\n",
    "\n",
    "\n",
    "**Low Evidence Indicator Usage:**\n",
    "\n",
    "A striking finding was the infrequent use of explicit evidence indicators. **Less than 7%** of all analyzed posts and comments contained either a URL or one of the predefined evidence-related keywords. This low rate occurred despite the often argumentative and opinionated nature of the discussions, where stances (particularly \"Anti-Musk\") were clearly expressed. This observation aligns with the initial hypothesis that evidence, at least in the form of easily detectable indicators like links or specific keywords, might not be a primary feature of these online exchanges, even when strong opinions are present.\n",
    "\n",
    "\n",
    "**The \"NotEnoughMuskSpam\" Anomaly:**\n",
    "\n",
    "The network visualization preparation (sizing nodes by comment count) revealed an unexpected and intriguing case study: the user **\"NotEnoughMuskSpam\"**. This user was, by a significant margin, the most active commenter in the dataset (63+ comments) and garnered substantial engagement (675+ karma within this data). Surprisingly:\n",
    "*   This highly active user was classified as **\"Neutral/Mixed\"** by OpenAI, despite a username suggesting a strong bias.\n",
    "*   They used **zero detectable evidence indicators** in any of their comments.\n",
    "*   Their average VADER score was slightly positive (~0.14), further aligning with the username's implication.\n",
    "\n",
    "This user represents a fascinating deviation. Their high engagement without relying on external evidence indicators, coupled with a \"Neutral\" classification that contradicts their username, raises questions. Possible interpretations include: the user primarily engages through questions, meta-commentary, or non-falsifiable assertions rather than claims requiring evidence; the GPT-3.5 model might have struggled with their specific style; or their activity pattern itself is a form of engagement that doesn't fit typical \"argumentative\" models. This case underscores the idea that high activity and influence in online discussions aren't necessarily tied to evidence-based argumentation. The second largest node being the AutoModerator (correctly neutral) serves as a baseline.\n",
    "\n",
    "**Network Structure Insights:**\n",
    "\n",
    "The prepared Gephi files now allow for visualizing these patterns. Plotting users (nodes) colored by their `dominant_openai_stance` and sized by `comment_count` should visually represent the stance distribution and highlight the prominence of users like \"NotEnoughMuskSpam\". Analyzing the connections (edges) can reveal if interactions primarily occur between users of similar stances (echo chambers) or if there's cross-stance engagement.\n",
    "\n",
    "**Vader Sentiment:**\n",
    "\n",
    "![Vader Sentiment](VaderSentiment.png)\n",
    "\n",
    "**Legend:**\n",
    "\n",
    "![Legend](Legend.png)\n",
    "\n",
    "\n",
    "\n",
    "**ProMusk:**\n",
    "\n",
    "\n",
    "![ProMusk](ProMusk.png)\n",
    "\n",
    "\n",
    "**AntiMusk:**\n",
    "\n",
    "\n",
    "![AntiMusk](AntiMusk.png)\n",
    "\n",
    "\n",
    "**Uknown:**\n",
    "\n",
    "\n",
    "![Uknown](Unknown.png)\n",
    "\n",
    "This analysis phase has successfully quantified stance and evidence usage, revealing a landscape dominated by Anti-Musk sentiment (among classified comments), very low reliance on explicit evidence indicators, and intriguing user behavior patterns like the \"NotEnoughMuskSpam\" case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Conclusions Based on Research Questions\n",
    "\n",
    "Based on the computational analysis performed on the collected Reddit data regarding Elon Musk from `r/technology` and `r/EnoughMuskSpam`, I can offer the following preliminary conclusions for my research questions:\n",
    "\n",
    "1.  **RQ1: To what extent do Reddit users cite external evidence or data?**\n",
    "    *   **Conclusion:** Explicit evidence indicators (defined as URLs or specific keywords like 'source', 'data', 'article') were used **very infrequently**. Less than 7% of all posts and comments contained such indicators. This suggests that, within these subreddits and this topic, arguments or statements frequently rely on assertion, anecdote, or implied knowledge rather than explicit external backing. *Further analysis is needed to confirm if this low rate significantly differs between the two subreddits.*\n",
    "\n",
    "2.  **RQ2: Do posts/comments containing explicit evidence correlate with higher levels of engagement or persuasion?**\n",
    "    *   **Conclusion:** Based on this initial analysis, there is **no clear positive correlation** between the presence of these specific evidence indicators and higher engagement (measured by score/karma). The most active and highly-engaged user identified (\"NotEnoughMuskSpam\") used zero evidence indicators yet achieved significant comment volume and karma. This suggests engagement in these discussions may be more strongly driven by factors like activity level, humor, alignment with community sentiment/stance, or controversy rather than the explicit citation of external evidence as defined here.\n",
    "\n",
    "3.  **RQ3: Under what circumstances do we see contradictory interpretations of the *same* piece of evidence?**\n",
    "    *   **Conclusion:** The methodology successfully identified URLs that were cited multiple times within the dataset, providing **candidates for investigating contradictory interpretations**. However, a detailed qualitative analysis comparing the text, sentiment (VADER), and stance (OpenAI) of comments citing the *same* URL is required to definitively answer this question. The framework is established, but the specific analysis of these instances was not completed in this computational pass.\n",
    "\n",
    "4.  **RQ4: Are these patterns different in subreddits with strict moderation policies versus those with more lenient or minimal rules?**\n",
    "    *   **Conclusion:** Clear differences were observed in **stance distribution**, with `r/EnoughMuskSpam` presumably showing a much higher concentration of \"Anti-Musk\" stances compared to the likely more mixed distribution in `r/technology` (pending confirmation via direct comparison). However, the **low overall usage of evidence indicators (<7%)** might be a **shared characteristic** across both subreddits for this topic, suggesting that community norms around explicit evidence citation might be similarly low in both contexts *for this specific type of discussion*, despite potentially different moderation styles or prevailing sentiments. The distinct stance profiles likely influence *how* arguments are made and received more than the *frequency* of citing external links or keywords using the methods employed here. Further analysis comparing interaction patterns within the Gephi network for each subreddit is needed.\n",
    "\n",
    "Overall, the findings suggest that while discussions about Elon Musk are polarized (predominantly critical in this sample), the explicit use of external evidence indicators is not a common feature. Engagement appears linked to factors other than providing such evidence, and user activity can be high even without it, sometimes in surprising ways (\"NotEnoughMuskSpam\"). The distinct stance environments of the subreddits are the most apparent difference identified so far."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
